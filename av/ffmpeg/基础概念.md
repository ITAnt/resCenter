## FFmpeg 基础概念



#### Bitstream Filter

1. 比特流滤波器作用在编码后的数据上，而不是未压缩的数据。
2. 在不解码的基础上执行比特流级别的修改。

示例

```shell
ffmpeg -i input.mp4 -codec copy -bsf:v h264_mp4toannexb output.ts
```

这个是把mp4容器格式改为ts容器格式，需要把h.264的封装格式从mp4改成annexb。

h.264编码有两种封装格式

1. 一种是annexb模式, 它是传统模式, 有startcode, SPS和PPS在Element Stream中.
2. 另一种是mp4模式, 一般Mp4, MKV, AVI都没有startcode, SPS和PPS以及其他信息被封装容器中. 每一帧前面是这一帧的长度值, 很多解码器只支持annexb模式, 因此需要对Mp4模式做转换.



#### 分离出多媒体文件中的音频流

FLV，MP4这些属于“特殊容器”。经过仔细对比后发现，调用av_read_frame()后得到的AVPacket里面的内容是AAC纯数据，就是那种不包含ADTS文件头的AAC数据。因此如果想要得到可以播放的AAC文件，需要在每个AVPacket前面加上7字节ADTS文件头。

#### 分离出多媒体文件中的H.264码流

FLV，MP4这些属于“特殊容器”，需要经过以下处理才能得到可播放的H.264码流

第一次存储AVPacket之前需要在前面加上H.264的SPS和PPS。这些信息存储在AVCodecContext的extradata里面。

并且需要使用FFMPEG中的名为"h264_mp4toannexb"的bitstream filter 进行处理。

```c
unsigned char *dummy=NULL;   //输入的指针  
int dummy_len;  
AVBitStreamFilterContext* bsfc =  av_bitstream_filter_init("h264_mp4toannexb");    
av_bitstream_filter_filter(bsfc, pCodecCtx, NULL, &dummy, &dummy_len, NULL, 0, 0);  
fwrite(pCodecCtx->extradata,pCodecCtx-->extradata_size,1,fp);  
av_bitstream_filter_close(bsfc);    
free(dummy);  
```

AVPacket中的数据起始处没有分隔符(0x00000001), 也不是0x65、0x67、0x68、0x41等字节，所以可以AVPacket肯定这不是标准的nalu。其实，AVPacket前4个字表示的是nalu的长度，从第5个字节开始才是nalu的数据。所以直接将AVPacket前4个字节替换为0x00000001即可得到标准的nalu数据。

```c
char nal_start[]={0,0,0,1};  
fwrite(nal_start,4,1,fp);  
fwrite(pkt->data+4,pkt->size-4,1,fp);  
fclose(fp);  
```

#### swscale图片缩放算法

> SWS_FAST_BILINEAR
>
> SWS_BILINEAR
>
> SWS_BICUBIC
>
> SWS_X
>
> SWS_POINT
>
> SWS_AREA
>
> SWS_BICUBLIN
>
> SWS_GAUSS
>
> SWS_SINC
>
> SWS_LANCZOS
>
> SWS_SPLINE

如果对图像的缩放，要追求高效，比如说是视频图像的处理，在不明确是放大还是缩小时，直接使用SWS_FAST_BILINEAR算法即可。如果明确是要缩小并显示，建议使用Point算法，如果是明确要放大并显示，其实使用CImage的Strech更高效。当然，如果不计速度追求画面质量。在上面的算法中，选择帧率最低的那个即可，画面效果一般是最好的。





#### 从内存中读取数据

关键点有两点：

- 初始化自定义的AVIOContext，指定自定义的回调函数
-  自己写回调函数

```c
AVFormatContext *ic = NULL;
ic = avformat_alloc_context();
unsigned char * iobuffer=(unsigned char *)av_malloc(32768);
AVIOContext *avio =avio_alloc_context(iobuffer, 32768,0,NULL,read_buffer,NULL,NULL);
ic->pb=avio;
err = avformat_open_input(&ic, "nothing", NULL, NULL);
```

**关键要在avformat_open_input()之前初始化一个AVIOContext**，而且将原本的AVFormatContext的指针pb（AVIOContext类型）指向这个自行初始化AVIOContext。当自行指定了AVIOContext之后，avformat_open_input()里面的URL参数就不起作用了。示例代码开辟了一块空间iobuffer作为AVIOContext的缓存。

read_buffer则是将数据读取至  buffer的回调函数。read_buffer()形式（参数，返回值）是固定的，是一个回调函数（填充函数）。

```c
//Callback
int read_buffer(void *opaque, uint8_t *buf, int buf_size){
	if(!feof(fp_open)){
		inttrue_size=fread(buf,1,buf_size,fp_open);
		return true_size;
	}else{
		return -1;
	}
}
```

#### 输出数据到内存中

```c
AVFormatContext* ofmt_ctx=NULL;
avformat_alloc_output_context2(&ofmt_ctx, NULL, "h264", NULL);
unsigned char* outbuffer=(unsigned char*)av_malloc(32768);
AVIOContext *avio_out =avio_alloc_context(outbuffer, 32768,0,NULL,NULL,write_buffer,NULL);  

ofmt_ctx->pb=avio_out; 
ofmt_ctx->flags=AVFMT_FLAG_CUSTOM_IO;
```



#### QP

​        Quantizer Parameter，量化参数，反映了空间细节压缩情况。值越小，量化越精细，图像质量越高，产生的码流也越长。如QP小，大部分的细节都会被保留；QP增大，一些细节丢失，码率降低，但图像失真加强和质量下降。

#### profile level

分别是BP、EP、MP、HP：

1. BP-Baseline Profile：基本画质。支持I/P 帧，只支持无交错（Progressive）和CAVLC；
2. EP-Extended profile：进阶画质。支持I/P/B/SP/SI 帧，只支持无交错（Progressive）和CAVLC；
3. MP-Main profile：主流画质。提供I/P/B 帧，支持无交错（Progressive）和交错（Interlaced），也支持CAVLC 和CABAC 的支持；
4. HP-High profile：高级画质。在main Profile 的基础上增加了8x8内部预测、自定义量化、无损视频编码和更多的YUV 格式。

#### 码率控制算法

​        动态调整编码器参数，得到目标比特数。为视频序列中的图像组GOP、图像或子图像分配一定的比特。现有的码率控制算法主要是通过调整离散余弦变换的量化参数（QP）大小输出目标码率。

#### 编码模式

- VBR

  Variable BitRate，动态比特率，其码率可以随着图像的复杂程度的不同而变化，因此其编码效率比较高，Motion发生时，马赛克很少。码率控制算法根据图像内容确定使用的比特率，图像内容比较简单则分配较少的码率(似乎码字更合适)，图像内容复杂则分配较多的码字，这样既保证了质量，又兼顾带宽限制。这种算法优先考虑图像质量。

- ABR

  Average BitRate，平均比特率 是VBR的一种插值参数。ABR在指定的文件大小内，以每50帧 （30帧约1秒）为一段，低频和不敏感频率使用相对低的流量，高频和大动态表现时使用高流量，可以做为VBR和CBR的一种折衷选择。

- CBR

  Constant BitRate，是以恒定比特率方式进行编码，有Motion发生时，由于码率恒定，只能通过增大QP来减少码字大小，图像质量变差，当场景静止时，图像质量又变好，因此图像质量不稳定。优点是压缩速度快，缺点是每秒流量都相同容易导致空间浪费。

- CVBR

  Constrained Variable it Rate，VBR的一种改进，兼顾了CBR和VBR的优点：在图像内容静止时，节省带宽，有Motion发生时，利用前期节省的带宽来尽可能的提高图像质量，达到同时兼顾带宽和图像质量的目的。这种方法通常会让用户输入最大码率和最小码率，静止时，码率稳定在最小码率，运动时，码率大于最小码率，但是又不超过最大码率。



#### 图像原始数据存储

在FFMPEG中，图像原始数据包括两种：planar和packed。planar就是将几个分量分开存，比如YUV420中，data[0]专门存Y，data[1]专门存U，data[2]专门存V。而packed则是打包存，所有数据都存在data[0]中。

具体哪个格式是planar，哪个格式是packed，可以查看pixfmt.h文件。注：有些格式名称后面是LE或BE，分别对应little-endian或big-endian。另外名字后面有P的是planar格式。



#### avcodec_decode_video2()解码视频后丢帧的问题解决

使用下面这段代码解码视频时，视频尾巴上会丢掉几帧。

```c
while(av_read_frame(ifmt_ctx,&packet) >=0)
{
    ret = avcodec_decode_video2(video_dec_ctx,vframe,&got_frame,&packet);
    if(got_frame)
    {
        packet.pts = av_rescale_q(packet.pts,video_dec_st->time_base,video_enc_st->time_base);
        write_video_frame(ofmt_ctx,video_enc_st,frame);
    }
}
```

  这是因为源视频中PTS与DTS的不同造成的。

av_read_frame()按照PTS顺序读帧的时候，如果此帧需要参考后面的帧，那么此时avcodec_decode_video2()是没有能力解码此帧的，表现为got_frame返回0。  

  比如说遇上如下EFGH四帧：

ID :  E F G H
KIND:  I B P P
PTS : 1 2 3 4
DTS : 1 4 2 3

那么顺序读到F时，由于F需要参考G帧，而此时我们还没读到G帧，我们是没有解码F的能力的，got_frame就返回0了。如果我们对此事不做处理，那么我们就会丢掉一个帧（但丢掉的未必是F，因为av_read_frame()和avcodec_decode_video2()是1:1调用的）。  

所以我们需要在while(av_read_frame())读完整个视频后，继续调用avcodec_decode_video2()把之前那些没有成功解码的帧都解出来。调用的次数就是之前got_frame返回0的次数。

```c
int skipped_frame = 0;
while(av_read_frame(ifmt_ctx,&packet) >= 0){
    ret = avcodec_decode_video2(video_dec_ctx, vframe, &got_frame, &packet);
    if (got_frame) {
        packet.pts = av_rescale_q(packet.pts,video_dec_st->time_base,video_enc_st->time_base);
        write_video_frame(ofmt_ctx,video_enc_st,vframe);
    }
    else
    {
        skipped_frame++;
    }
}
 
for(int i=skipped_frame; i>0; i--)
{
    ret = avcodec_decode_video2(video_dec_ctx, vframe, &got_frame, &packet);
    if (got_frame) {
        packet.pts = av_rescale_q(packet.pts,video_dec_st->time_base,video_enc_st->time_base);
        write_video_frame(ofmt_ctx,video_enc_st,vframe);
    }
}
```

