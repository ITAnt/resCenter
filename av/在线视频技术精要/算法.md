# 算法

当前人们讨论的算法，除基础的数据结构、排序、查找、规划、变换之外，更关注的是机器学习、深度学习、计算机视觉、自然语言处理等相关算法。

## 机器学习

简要而言,机器学习期望从数据中学习到结果,如果可以获得一组特征和结果的对应关系作为数据集,通过数据集和预设模型的计算可以得到模型,而习得的模型可被用于分类和回归任务的处理,也即通过输入的特征值获得离散或连续的结果。这就是不通过直接的分析和逻辑推理下手，而是通过数据和模型训练，用丰富的“经验”解决问题。
从统计和概率理论出发对问题求解,虽然在模型为何有效(也即可解释性)上尚存缺陷,但由于近年来大数据技术和计算能力的发展,数据样本获取和模型计算的成本大幅降低,成为在许多情况下超乎想象的有效手段。

### 分类

- 监督学习

- 无监督学习

  不需要数据标注，可直接对输入数据集进行建模

- 半监督学习

  综合利用有标注和无标注的数据，得到合适的分类函数

### 常见的算法和研究分支

- 线性模型
- SVM
- K近邻
- 决策树
- 随机森林
- GBDT

#### 线性模型

​	线性模型是机器学习最基本的算法类型，它试图学到一个通过多个特征（属性）计算的线性组合来预测的函数，简单的线性回归形式如y=ax+b，其中，x代表特征，而y代表结果，一旦a和b的值能到确定，模型即得以确定，此时若输入新的x就可以推算新的y。

​	用于确定a和b取值的过程，称为训练过程，训练过程需要一定数量的数据才能完成，也即是许多已知由x到y的映射，其中单一的一组映射称为样本，许多映射的集合则称为数据集。在训练过程中，通过数据进行一系列的计算，可以帮助确定a和b的值。

​	一个模型在训练时的计算时通常包括两部分：首先是模型本身即由x得到y的算式；其次是损失函数，又称目标函数，用于描还系統在不同参数值下的损失、当使用数据训练模型时，参数的变化方向将向损失函数最小的逼近。

​	训练模型的目标应是使其善于应对新的数据,即**泛化能力**,当输入从未见过的特征值时,也可以得到满意的预测结果。为达成此目标,通常需要较多的数据,保证训练过程更可能对未知的分布有充分采样,而数据通常可被划分为训练数据和测试数据,用训练数据获取模型,用测试数据评估模型的效果。

​	使用线性回归能够预测数据趋势，还可以处理分类问题。除线性回归外,**经典的线性模型中还包括逻辑回归**,逻辑回归可以视为广义的线性回归,其表现形式与线性回归相似,但使用逻辑函数将ax+b映射为一个隐状态,再根据隐状态的大小计算模型取值,其损失函数是最小化负的似然函数。

线性模型的**缺点**是难以预测复杂的行为,并容易出现过拟合，

#### 决策树

​	决策树是另一类常见的机器学习方法,其模型是一个树型结构,也可看作有向无环图,其中树的节点表示某个特征,而分叉路径代表不同的判断条件,数据将从根节点行进到叶节点,依据特征进行判断,最终在叶节点得到预测结果。常见的决策树算法有ID3、C4.5和CART等,其区别主要在于**依据什么指标来指导节点的分裂**。例如,ID3以增熵原理来确定分裂的方式,C4.5在ID3基础上定义了信息增益率,避免分割太细导致的过拟合,而CART使用的则是类似熵的基尼指数。

​	与线性模型类似，决策树也包括**分类树**和**回归树**，其优势是易于理解、实现，也易于评测，但**缺点**是训练最优的决策树可以被证明为完全NP问题，因此**只能使用启发式算法**，并且容易过拟合，通过对特征的选择、对数据的选择和对模型的剪枝能够缓解。此外，决策树的平衡也十分脆弱，较小的数据变化训练出的树结构可能大为不同，这时可以通过随机森林等方法解决。

#### 随机森林

​	随机森林（Random Forest）是集成算法的一种，其主要概念是将多种训练出的模型集成在一起，将一些较弱的算法通过集成提升成为较强的算法，泛化能力通常比单一算法显著地优越。随机森林本身是一个包含多个决策树的分类器，其输出类别由个别树输出的类别决定，其多样性来自数据样本和特征的双重扰动。

​	与随机森林代表的 Bagging 方法（均匀取样）有所区别，**Boosting 方法**意图根据错误率进行取样，对分类错误的样本赋予较大权重，可以看作集成算法不同的思路。此外，Bagging方法的训练集可以相互独立，接受弱分类器并行，而 Boosting 方法的训练集选择与前一轮的训练结果相关，可以视作串行，其结果往往在精度上更好，但难以并行训练。

​	Boosting 方法的代表算法是GBDT （Gradient Boost Decision Tree，梯度提升决策树），这里GBDT 学习的实际是之前所有树得到结论的残差。GBDT 可以处理离散和连续的数据，几乎可以用于所有的回归问题和分类问题，常见的 Xgboost库可以被看作遵循Boosting 思想决策树的优化工程实现，除 CART 树外，它还支持线性分类器作为基分类器，增加了损失函数中的正则项以防止过拟合，在每一轮学习后会进行缩减等。

​	贝叶斯分类器是另一种常见的构造分类器的方法，追求分类错误最小或平均风险最小，其原理是通过某个对象的先验概率，假设每个特征与其他特征都不相关，利用贝叶斯公式算出其属于某一类的概率，选择具有最大可能性的类别。

​	在不对问题做任何假定的情况下，并不存在一种“最优”的分类方法，如果说在特征数量有限的情况下，GBDT 和 Xgboost应当是首选尝试方案的话，支持向量机（即 Support VectorMachine，SVM）则是另一项利器，适于解决样本数量少、特征众多的非线性问题。由于期望区分的集合在有限维空间内可能线性不可分，SVM 算法通过选择合适的核函数定义映射（从原始特征映射到高维特征空间），在高维或无限维空间构造一个超平面，令其中分类边界距离训练数据点越远越好，以此进行分类和回归分析。

与上述的算法不太一样，**K近邻算法**是一延迟分类算法，即其几乎没有训练过程，相反主要的计算发生在预测过程。K近邻算法的原理是在给定数据中，基于距离找出训练集中与其距离最近的K个样本，基于其信息使用投票法或均值计算进行预测，距离可用于计算的权重。由于训练数据的密度并非总能保证在一定距离范围内找到近邻样本，可以采取降维的方法，即将高维的特征空间转换为低维，常见的方法包括主成分分析、线性判别分析、拉普拉斯映射等，而降维亦可通过度量学习的方法习得。

**聚类**是无监督学习的典型算法类型之一，聚类算法意图将数据集中的样本划分为若干集合，然而不同集合的概念并非预先设定，相反，属于同一集合的样本其特征取决于样本之间的相似性，也即距离长短，集合的特征可由使用者命名。常用的聚类算法有K-Means算法、高斯混合聚类等，其既可以用于直接解决分类问题，也可作为其他任务的前置任务。特征选择的思路主要包括在训练前对数据集进行特征选择，将模型性能直接作为特征子集评价标准，融合特征选择与学习过程等几类。

​	半监督学习需要应对的往往是仅有少量标注数据的情况，此时，若从已标注数据和未标注数据之间的联系入手将是自然的方式。半监督学习常见的假设包括**平滑假设**，假定位于稠密数据区域的距离较近的样本属于同一分类；**聚类假设**，假定标注过的数据与未标注的数据属于同一集合时，它们也大概率属于同一分类；**流形假设**，假定高维数据嵌入低维时，当样本位于低维流形的局部邻域时，它们大概率属于同一分类。半监督学习的分类方法又有基于差异的方法、生成式方法、判别式方法、图方法等。

​	概率图模型是用图来表示变量概率依赖关系的方法，一幅概率图由节点和边构成，节点表示随机变量，边表示变量之间的概率关系。它们又可以被分为两类：一类是有向图模型，即节点之间的边包含箭头，指示随机变量之间的因果关系；另一类是无向图模型，节点之间不存在方向，常用于表示随机变量之间的约束。常见的概率图模型包括马尔科夫场、隐马尔科夫模型、条件随机场、学习推断、近似推断、话题模型等。图模型的主要好处是利于快速直观地建立描述复杂实际问题的模型，从数据中发掘隐含的信息，并通过推理得出结论。

​	强化学习是机器学习中另一较大的分支方向，不同于前文所处理的分类、回归、聚类等问题，**强调基于反馈采取行动，以取得最大化的预期回报**，即建立一个主体通过行为获得的奖励或惩罚，修正对行动后果的预期，得到可以产生最大回报的行为模型。与一般的监督学习的模式不同，强化学习的反馈常常需要延迟获得，也即在多个步骤的行动之后才能获取到奖惩结果，其重要之处在于探索未曾尝试的行动和从已执行的行动中获取信息。可以想见，其适应的数据也将是序列化、交五性、带有反馈信息的。
​	考虑行动的模型可以马尔科夫决策过程（Markov Decision Process，MDP） 的描述，即系统的下个状态不仅与当前状态相关，亦与当前采取的行动相关，需要定义初始状态、动作集合、状态转移概率和回报函数。由于立即回报函数难以说明策略的好坏，还需要定义值函数表明某一策略的长期影响，而求取 MDP的最优策略，也即求取在任意初始条件下，能够最大化值函数的策略，对应的方法有动态规划法、蒙特卡罗法、时间差分法（结合动态规划和蒙特卡罗法的方法，如I Sarsa 或Q-Learning 算法）等。

​	从宏观上讲，机器学习方法不论在前文提到的编码、流媒体、搜索等方向，还是后续将讨论的个性化推荐、广告投放等领域，均存在广泛的应用，并仍有极大的发展空间。机器学习不但可以帮助从数据中获得潜在的知识，也令许多以往难以实现的功能得以成为现实。

构建有价值的机器学习应用将考虑几个主要的因素。

1. 获取有价值的数据，包括运行过程和结果。
2. 寻找可以被优化的目标，为目标优化可使用的指标。
3. 找到合适的算法和充分的计算资源。
4. 构造数据闭环，保证模型的可评估及可持续提升。

## 深度学习

机器学习中分支众多，其中近年来最为火热的当属肇端于神经网络的深度学习方向，由于其在图像处理、语音识别，自然语言处理等问题的解决上，爆发出比较于传统方法取得的压倒性优势而受到瞩目。

### 常见的算法和研究分支

神经网络，直到20世纪80年代，使用前向结构和BP 算法的多层感知机（MLP） 才被推广到广泛的应用场景。

神经网络的基本成分是神经元，其中a 代表输入向量的各个分量，w代表神经元各条边的权值，b为偏置值，f为激活函数，而t为输出结果。多层感知机由多个神经元组成，每一层均有自己的输入 （中间层或称隐藏层的输入为前一层的输出），与其他机器学习算法相似，神经网络的最终输出可用于解决分类和回归问题。

#### 深度神经网络	

深度神经网络即DNN，是至少存在一个隐藏层的神经网络，可为复杂的非线性系统提供建模，通常使用**梯度下降算法和BP 算法**结合进行训练。与其他机器学习算法类似，深度神经网络同样容易面临过拟合和计算负载较高的问题，可以通过权重递减、稀疏化、Mini-batch、Dropout 等方法缓解。

#### 卷积神经网络

卷积神经网络（即 Convolutional Neural Network，CNN） 是由一个或多个卷积层和深度神经网络连接组合，同时还包含池化层 （Pooling Layer） 构成的网络结构。卷积层由若干卷积单元组成，其用途是提取输入的不同特征。如果网络中有多个卷积层，则较前的卷积层往往只能提取较低级的特征，而后续的卷积层则更可能提取到复杂的特征。池化层则通常起到降采样的作用，通过计算子区域（如图像的2X2区域）的平均值或最大值，降低参数的大小。
卷积神经网络因其强大的特征提取能力和适于向量计算的特点，在提出后的时间里得到了长足发展，在此基础上变化出了多种网络结构，其效果也逐步提升，2012年提出的 AlexNet （见图8-11），2014年提出的 VggNet、 GoogLeNet，2015年提出的 ResNet 等都是经典的网络结构。

深度学习虽已得到飞速发展，但未来5~10年中，仍然可以期待其处理模型更加通用，预测准确性进一步提升，计算方法愈加高效，适合处理的问题越来越多，成为解决各类分类、回归、优化、生成问题的利器。在全自动训练（参考 Google的 AutoML 项目）、多模态学习、更复杂的生成模型、元学习等多个方向都值得开发者持续关注。

## NLP 自然语言处理

自然语言处理（即 Nature Language Processing，NLP） 是人工智能的分支领域，其中涵盖计算机对人类语言的认知、理解和生成。自然语言处理的难点在于，在不同语境中，同样的词或短语会有完全不同的涵义，包括词句本身不同的涵义以及上下文中体现的意图，而人类的语言系统中，还存在一些天然地难以量化的因素，如习惯抑或品味。但是，不论机器对人操作意图的理解（例如搜索），机器对内容的理解（视频分析），还是人对机器表达的接受（翻译和对话），唯有解决这些问题，才能搭建起人与机器沟通的桥梁。

## 计算机视觉技术

​	计算机视觉包括**图像处理和模式识别**，首先，它可以帮助人们把输入图像进行转换，通常被用于预处理，提取后续流程所需的特征。其次，根据从图像中获取的统计信息或结构信息，可将图像分成预设的类别，如辨识出形状、照片和色彩。

### 常见的问题与算法

由于香农定理，成像时在采样频率一半之上的频率将产生失真的信号，而在图像处理过程中，偏差也不可避免地产生，平衡和补救实质上不可或缺。例如对通过彩色滤波器得到的图像进行插值，在获取 RGB 图像的同时去除马赛克。又如将给定图像的白点调整到靠近纯白位置，对有色的强照明环境作用将十分明显。此外，对于由压缩引入的失真进行补偿，也是现代编码器的重要组成。

​	最简单的图像处理如像素运算，也即由原始像素计算得到输出像素，通过设计合适的转换函数，例如在像素的各色彩通道加入不同的正负数值，将改变图像的亮度、色调和饱和度。不同的函数将带来不同的效果，例如覆盖算子可以帮助合成图像，而亮绿色背景下的抠图常通过 Mishima、Bayesian 等算法实现，复杂背景下的抠图亦有多种算法，将提取出的部分对边缘处理，即可合成到新的背景中。

​	对于图像的色调调整，图像平滑、锐化或噪声去除任务，邻域算子能够利用给定像素周围的像素值决定目标像素对应的结果。例如带通滤波，可用于滤去低频和高频信号；导向滤波，只对方向上具备局部一致性的边缘起作用；中值滤波，常应用于对异常值进行过滤。

##### 图像金字塔

当需要改变图像分辨率时，可以利用不同的插值（如双线性插值、双三次插值）进行上采样，利用二项滤波器进行下采样。若需要使用多种分辨率，常会构造一个**图像金字塔**，即以金字塔形状排列的多张图像组合，其中所有图像均来自于同一张原始图片，通过梯次地进行下采样方式获得。例如高斯金字塔和拉普拉斯金字塔，在边缘检测和图像增强上均有广泛应用。此外，还有小波滤波器，允许以平滑方式把信号分解为频率成分。

​	倘若需要图像不同部分能够自由地变形，可将图像分解为三角形并由三角形顶点确定仿射运动模型，还可以使用四边形网络。

##### 检测与匹配

为提取图像中的信息，检测与匹配其中的特征十分重要，在图像中，一些特殊的位置即关键点特征，而目标的**边缘**则是另一类重要特征，对连续图像之间也即视频中的匹配又可称为**跟踪**。在图像的某个区域，如果有较大的对比度变化，包括亮度、颜色和纹理的信息，则较容易定位（如杯子或海水的边缘），传统而言有多种特征检测器被开发出来，但由于特征匹配面临的可能包括尺寸变换、旋转、遮挡或仿射后的图片，在不同状况下提取均有稳定表现的特征比较高效，例如 SIFT、SURF、HOG、LBP、Haar等算子。

##### 匹配和分割

当提取到图像特征之后，接下来的问题是**匹配和分割**。匹配的问题在于解决需要在何种距离的范围内匹配，如何通过映射到某种索引结构中加速比对，分割则与聚类问题有些类似，即判断哪些像素应该被划分为同一区域，传统的分割方法包括基于活动轮廓、分裂与归并、均值移位、归一化切割等。

##### 运动估计算法

除在编码器中的应用之外,**运动估计算法**还可用于解决图像拼接和视频稳定性、插帧、视频修补等问题，好的估计需要找到合适的误差度量方法以及快速的搜索方法。搜索时在较小搜索范围内可采用分层估计的方法，而较大范围则可考虑基于傅里叶变换的方法，在多个独立像素的情况下考虑光流方法，对包含大量遮挡的运动中使用层次运动模型，其中往往需要引入图像分割的知识，当已然逼近最近的像素时可以利用基于图像函数泰勒展开的逐次求精法得到亚像素估计。

##### 图像配准

图像配准的目标是找到一种变换,令变换图像后两幅图像的相似程度达到最大，配准方法可基于空间维数，或者基于内部特征如点、面像素，基于外部特征，如人为标记，根据变换的性质等分类。通过二维和三维方法对其进行变换，例如平移、旋转、仿射、投影、刚性、缩放等，基于其特征，能够完成形如从多幅图像中生成全景图的任务。

##### 二维推测三维

一个常见的特殊问题是从二维的点中估计物体的三维姿态，对于模型重建而言十分重要，此领域中包括简单的线性算法和追求精确的迭代算法，通过配准结果可以帮助推测摄像的位置和镜头的旋转和畸变程度。当存在多个摄像源时，可以通过三角测量法确定点的三维位置。当摄像位置处于运动情况时，需要同时估计目标的三维结构和摄像机位置，通用的方法有光束平差法等，可以广泛地运用于增强现实、机器人导航等场景中。

##### 图像合成

在图像配准之后，若需生成合成的图像，则首先需要考虑拼接时的平面，针对较大的视角情况，圆柱面投影或球面投影将成为首选，当屏幕并非平面时，还需对合成的图像进行再转换以映射到屏幕上。在选择像素时，可采取的策略包括包括中心加权法、最大或最小似然度等，分别倾向于选择图像中心附近的物体，倾向保留重复出现的像素点或保留运动轨迹。最后，为在合成的图像中平滑其差异，可供选择的方法包括拉普拉斯金子塔融合、梯度域融合等。

在推测物体三维形状的过程中，表面的阴影或纹理的透视变化、随焦距模糊的程度均可以提供方向和形状的信息，若能够使用可选择性开关的光源，其效果与多个摄像位置相似，根据不同光源的反射图，可以恢复出表面的方向估计。使用主动照明的方式同样可以获取足够的深度信息，包括使用变化的阴影，持续的高速扫描和特殊的感知硬件。

##### 重建纹理

得到物体的三维模型后，最后的步骤将是重建纹理，由于重建时源图像常常不唯一，可以采用的方式有使用视图相关的纹理映射，即给定虚拟摄像视图，比较其与源图像在像素上的相似性并将源图像按照权重混合，其权重与虚拟视图和源图像角度成反比，或者为每个点均估计出其光场。

### OpenCV

OpenCV的全称是Open Source Computer Vision Library，它实现的算法追求快速和实用，支持包括 Android 和 IOS在内的跨平台编译和运行，主要开发语言是C和 C++，但也提供 Python等高级语言的接口。软件支持通用输入输出模块处理图像和视频，各种动态数据结构，矩阵、向量和相关的数学操作。

#### 基本数据结构 Mat

OpenCV最基本的数据结构称作 Mat，是 Matrix 的缩写，结构中包含 Header 和 Pointer，Header 中描述了矩阵的大小、存储方式和地址信息，Pointer 中则是指向像素值的指针。图片可以被定义为 Mat类型，当使用的时候，若要复制数据，则需要调用深度拷贝的函数，Mat类型按照逐行方式存储数据，可以通过形如 M.row、M.nCols 等成员可以轻易得到图像的行数和列数，通过 M.channels（）等函数也可以容易地获知诸如通道数等信息，Mat结构还可以按照连续的方式存储像素，方便遍历。

#### 功能

OpenCV 支持的模块包括各种基本的滤波、点和边缘的检测、采样和插值、色彩转换、直方图、图像金字塔、轮廓处理、距离变换、模板匹配、拟合、摄像位置标定、矩阵估计、光流、运动分割、跟踪、特征识别等。在实践中，OpenCV 可以涵盖大部分简单的场景，在特殊场景下，可能需要对其进行二次开发，以支持实际的情况或提升效率。

## 视频理解

作为计算机视觉的分支，视频理解着力于从视频中生成出有意义的知识（信息）并予以支撑各种各样不同的应用。

### 面临的问题和解法

视频理解通常有两种解决的思路：一种是将问题分解成不同层次、不同目标的子问题，按照知识生产的角度建立体系。

其次是情感信息和场景抽象，情感分析的目的是将视频片段在用户可理解的维度反映出来，同时也可增加更高级信息处理的维度。通过模型辨识出的情感信息可以直接或间接地应用。

基于理解场景的能力，应用模型还可以生成描述，包括对图像的描述和对视频的描述。通过CNN 将图像或视频提取特征，再用时序神经网络（如 LSTM） 生成文字，当图像或视频中有多个目标、多个事件同时发生时，可通过在不同区域分配注意力，分别进行描述并将句子结合成段落。

完整的视频理解意味着利用包括视频流、音轨以及字幕在内的全部知识，同时利用内容的元数据，甚至囊括用户评论和弹幕信息等，由此构成称体系的知识。

## 附

#### 过拟合

过拟合指的是模型因为使用过多参数或冗余的结构，导致模型**虽然与训练数据可以完美地拟合，但不能很好地预测新数据的结果，在泛化能力上较差**。为避免训练出的模型过拟合，需要通过交叉验证、正则化等方式来发现和解决。正则化是为损失函数加入正则化项的方法，可视为一种惩罚手段，引导模型的训练倾向于选择满足限制条件的梯度减少的方向，以限制模型的复杂度，解决过拟合问题。

#### 稀疏化

稀疏化通常指只保留模型中一些重要的连接，通过权重值量化来进行一些共享等方法，可以降低计算的压力。

#### 高斯金字塔

高斯金字塔将原图像作为底层图像，利用高斯核对其进行卷积，然后对卷积后的图像进行下采样得到上一层图像，如此反复迭代获得。

#### 拉普拉斯金字塔

拉普拉斯金字塔由高斯金字塔每层图像减去其上一层图像上采样并进行卷积后的预测结果得到残差组成，由拉普拉斯金字塔可以重建高斯金字塔。

#### SIFT

SIFT(即尺度不变特征转换, Scalenvariant- Feature Transform)善于检测局部特征,通过搜索所有尺度上的图像位置,拟合尺度空间上的极值点,赋予128维的向表示,其特征点十分稳定,往往不受尺度、光照、仿射或噪声影响,SURF是对SIFT的改进,用盒状滤波器代替高斯核,速度快且稳定性更佳。

#### HOG

HOG(即方向梯度直方图, Histogram of Gradient)通过计算图像局部区域的梯度方向直方图构成特征，算子首先将颜色空间归一，分别在水平和垂直方向进行梯度计算，在图像中划分区域并统计梯度方向直方图，对重叠区域内的块进行对比度归一化，将所有区域的直方图向量组合得到完整特征。它可以很好地描述局部的形状信息，但并不具备尺度和旋转不变性质。

#### LBP

LBP(即局部二值模式, Local Binary Pattern)致力于描述图像的局部纹理特征,定义在某个大小的窗口内,以窗口的中心像素为阈值，将相邻像素的灰度值分别与其比较，得到中心像素点的LBP值，作为纹理特征，窗口可以是方形或圆形,具备旋转不变性和灰度不变性。

#### Haar

Haar(即哈尔特征)可以分为线性特征、边缘特征、中心和对角线特征，反映出图像的灰度变化情况，通过改变特征模板的大小和位置，可以穷举出巨量的特征，但由于使用积分图结构，特征可以在常数时间内计算，对人脸检测十分适用。