# 编码

#### 香农信息熵

香农信息论原理中曾给出了“信息熵”的概念，熵度量了消息中所含信息量的多少,其中去掉了由消息固有结构决定的部分，意味着越随机的消息含有的熵越大，其理论论证了数据压缩的可能性和极限到底有多少,以及在允许一定失真的情况下,可能的压缩极限在哪里,这也是整个压缩的理论基础。

H(X) = - sum(p(xᵢ)logp(xᵢ))  i 为 1~n

式中，关于随机变量X的嫡值，可定义为对有限样本求概率质量函数（即pt)，离散随机变量在各个特定取值上的概率)，函数结果与其对数乘积的和，其中对数以2为底的话，嫡的单位为比特（Bit),举例而言，如果需要表达64个概率相等的物品，最少需要6Bit。

#### 压缩

对于无损压缩，主要有简单的行程长度编码、字典编码，以及 PPM（通过部分匹配进行预测)、熵编码等思路;对有损压缩，可考虑的方向有离散余弦变换、分形、小波变换、向量化、特征编码等。
数据压缩的理论与统计学科密不可分，可以被看作找到数据的特殊差异，再针对差异进行不同处理，针对较大份数据找到最佳压缩方式不是件容易的事，不同压缩方法可视作对最优解不同的逼近，机器学习或深度学习不论在寻找差异还是预测序列的概率上都可以扮演重要角色。

## 音频

### 音频编码

如同经过编解码后视频质量会下降一样，音频编解码可能引入一定的失真和噪声，好的编码器可以尽量避免这一点。人耳的听觉频率范围大致在20~20000Hz，在该频率范围之外的声音人耳是无法听到的，可以视为冗余信号，此外人耳存在频率掩蔽的效应。当某个频率的声音能量小于某个值，将不会被人听到。当存在能量较大的声音的时候，周围频率的阈值会提高。类似地，在较强信号发生的时间段,较弱信号亦将被掩蔽，从而人耳无法听到。

音频信号的压缩，通常是波形编码、参数编码等多种技术混合的编码方式,其中波形编码是根据采样的数据，建立一定的波形以符合原始波形，保留较多的细节和过渡特征。参数编码则是根据不同信号源，提取特征参数(例如共振峰、线性预测系数等）并编码。实践中许多编码器混合使用了多种波形和参数编码的技术,并将信号分解为不同频率范围，而根据不同的分布特性采取不同压缩策略，以在提升压缩率的同时保留好的声音质量。

#### AAC/HE-AAC

​	首先，AAC 编码器可通过滤波器组得到频域的频谱系数，并通过TNS (Temporal Noise Shaping,时城噪声修正)技术修正量化噪声的分布，对语音信号剧烈变化时音质提升巨大。与视频编码器的流程类似，AAC 的编码器同样借助了预测、量化、以及熵编码等技术。

​	在MPEG-4中，AAC加入了LTP (Long Term Prediction)技术和PNS (Perceptual Noise Subsitution,即忽略类似噪声信号的量化)技术，对低码率下的音质和编解码效率作了进一步提升。此外，MPEG-4中最主要的变化，就是支持了AAC+ (也即HE-AAC)。
​	HE-AAC混合了AAC与SBR、PS技术(加入PS则被称作HE-AACv2D)。SBR是Spectral Band Replication 的缩写，因为音乐的能量主要集中在低频部分，高频段虽然重要但幅度很小，SBR针对频谱切分成不同频段，对低频保留主要成分，对高频部分放大编码以保证音质，整体上提高了效率。PS指Parametric Stereo,对两个声道的声音去掉相关性，仅保留其中一个声道的全部信息，对另一声道仅描述声道之间的差值。

​	AAC的编码过程，大致而言是将音频数据通过PQF ( 多相积分滤波)技术分离为不同子带，对每个子带传输独立的增益，由增益整形后的子带数据根据不同信号以MDCT (改进的离散余弦变换)，使用转换Kaiser-Bessel (KBD)类窗和正弦窗进行转换，由非均匀量化器实现量化。
​	与AVI的胶粒合成思路类似，AAC中的PNS (Perceptual Noise Subsititution,知觉噪声替换)技术能以参数编码模拟噪声，即在识别音频中的噪声后将之从编码流程中去除，而采用某些参数告知解码器，由解码器使用随机方式重新生成类似噪声。

​	在解码时基本为编码的逆过程，首先进行无噪声解码(即哈夫曼解码)，其次进行反量化，然后判断联合立体声的模式(AAC具备两种联合立体声的表达模式，MS和Intensity 模式)进行解码，根据是否使用PNS的判别结果进行计算修正，再应用TNS进行瞬态噪声整形，最后将频域数据填入IMDCT滤波器转换为时域，并进行加窗和叠加。如果使用SBR编码，此时还需进行频段复制，得到左右声道的PCM码流。

##### 封装

​	编码器所生成的基本格式称作EP，在存储和网络传输中为便于使用，又基于EP对音频负载规定了不同层次，不同用途的封装格式，譬如LATM、ADIF、ADTS、LOAS等。

​	ADIF 封装的特征是仅有一个统一的头标记了解码器所需的参数信息，解码必须从明确定义的位置开始，多用于文件存储。ADTS则是一个有同步字的流，解码可以从流的任何位置开始，因为每一帧上都有固定字符长度的ADTS头，包含了解码信息。

​	LATMLOAS 则是MPEG-4加入进来的另一种封装格式， 较ADTS效率更高，LATM帧由AuiiesitiCoin与负载组成，其中AudioSepcificConfig 可以通过带内或带外传递，既可以每帧包含这个对象，也可以通过其他方式发送，这是因为，通常一个音频流中的配置不会变化，所以采取带外传输可以去除传输的冗余。LATM中包含的负款可以容易地映射到RTP包的负载上传输，而 LATM 封装的帧再加入同步层即为 LOAS 封装，ADTS 和LATMLOAS格式之间可以简单地相互转换。

​	AAC编码的数据块可能有SCE (单通道元素，通常由一个ICS组成)、CPE (双通道元素，由两个共享信息的ICS和联合编码信息构成)、CCE (耦合通道元素)、LFE (低频元素)、DSE (数据流元素)、PCE (程序配置元素)、FIL (填充元素，如SBR)等。

#### AC3 或 EAC3

杜比的环绕立体声 AC3 或 EAC3。

由于杜比针对AC3或EAC3的解码器要求收取专利费，许多设备本身并不支持其解码，而是通过Psstrough模式（透传）发送到后面支持解码的设备(可以通过SPDIF或HDMI 线，通常是电视机或功放)，所以通常传输时AC3或EAC3都难于通过常用的DRM加密(或存在HDCP漏洞)。

### 音频编码质量评价

#### 主观评价

- DRT (Diagnostic Rhyme Test,音韵字评价)
- MOS (Mean Option Score,平均意见分)
- DAM (Diagnostic Acceptability Measure,满意度测试)

观评价两个方向，其中常用的主观评价方法包括DRT (Diagnostic Rhyme Test,音韵字评价)、MOS (Mean Option Score,平均意见分)、DAM (Diagnostic Acceptability Measure,满意度 测试)等。

#### 客观评价

客观评价标准的常用算法有PEAQ (感知音频评价)，其对音频进行特征提取后计算出多个模型输出变量，最后由神经网络将参数融合成为客观评价分数ODG,其他技术指标还包括失真度( 谐波失真、相位失真或抖晃失真)、频响、瞬态响应、信噪比等。
测量 SNR的工具可使用CompAudio, ODG可选取GstPeaq, 针对多通道音频(如杜比环绕立体声)进行评估。

## 视频

### 视频编码

#### 编码思路

视频的压缩方法主要包括去除空间上、时间上、统计上以及感知上的冗余信息等几个主要努力方向。视频由一系列连续的图像组成，在某一幅图像之中就存有大量的冗余。

#### 编码发展

##### 视频编码的发展

主要使用的技术都在变换编码、预测编码和嫡编码的范畴内，不论MPEG-2还是H.264，HEVC还是VP9，都大致相似，即使在较新的AV1以及规划中的H.266内，也没有大的变化。

#### 基本概念

##### GOP

现代的视频编码器里存在GOP(Group of Pictures）的概念，代表了一组连续的图像帧，通常而言，GOP中的第1帧编码为**I帧**,此外还有P帧和B帧的概念。I帧表示关键帧(KeyFrame)，其解码时不需要引用来自其他帧的信息即可完成(与图片编解码较为相像);P帧表示前向参考帧(Predictive Frame)，体现了当前帧与前面参考帧的区别，需要依赖前面的I帧或P帧才可以解码;B帧通常又叫作双向参考帧(Bi-directional Interpolated Prediction Frame),记录了当前帧与前后帧的不同，需要依赖其前后两个方向的I帧或P帧才可以完成解码。

可想而知，解码时依赖其他帧的信息越多，说明当前帧的冗余越少，压缩率越高，一个简单的估算可以认为I帧、P帧、B帧的大小比例可达到9:3∶1。

##### PTS

Presentation Timestamp （显示时间戳）

##### DTS

Decode Timestamp (解码时间戳)

##### IDR

**在H.264和 HEVC中,还定义了一种IDR帧**，其含义是，从IDR帧开始，所有后面的帧都不会参考该IDR帧之前的帧，而普通的I帧可以被其前后两个方向的其他帧所引用。

#### MPEG-2

具体来说，MPEG-2编码器使用了DCT (Discrete Cosine Transform，离散余弦变换)运动补偿和霍夫曼编码，对数据从大到小定义了 Sequence、GOP、Picture、Slice、宏块(MacroBlock）、Block等多个层次。GOP的概念上面已予介绍，在 MPEG-2中宏块定义了4:2:0、4:2:2、4:4:4 不同结构，Block则代表了8×8个采样值。
在帧内编码时，MPEG-2只应用DCT变换和量化步骤，而帧间编码时，首先将原图和预存的预测图进行比较，计算出运动矢量,和参考帧一并生成原图的预测图。然后由原图和预测图的差值得到差分图像,进行DCT变换和量化步骤。最后经历无损编码阶段得到最终的结果。

MPEG-2编码器应用到的值得一提的详细技术点还包括:Z字扫描、游程编码”和熵编码、运动估计和码率控制。

虽然 MPEG-2编码器已经具备了视频编码器的基本特征,但从 MPEG-4 等编码格式开始,才开始从基于像素的编码转为基于对象和内容的编码。譬如 MPEG-4编码器引入了 VOP( Video Object Plane)作为核心概念,包含对象提取、编码可分级、半像素搜索、重叠运动补偿、重复填充等技术。H.264 编码器加入了更小的变换块、可变块大小运动补偿、1/4采样精度的运动补偿、加权预测、多参考帧运动补偿、循环去块效应滤波器、基于上下文的熵编码等数十项较大的新编码工具或改进。

##### DCT

DCT 类似于只使用实数且长度为两倍的离散傅里叶变换，常在信号和图像处理或对数据进行有损压缩时候使用，DCT变换本身是可逆的，它最大的特点是“能量集中”,由于大多数声音或图像信号的能量集中在变换后的低频部分，以此对高频部分进行舍弃，可以达到压损率大而损失较少，保留信息更多的目的。

##### 量化

量化指将信号的连续取值近似为多个离散值，在MPEG-2编码中，量化过程就是以某个量化步长除以DCT 系数，量化步长越小就保留了更多的信息，但数据量就越大，因为不同的DCT 系数对人的感知重要性并不相同，所以对DCT变换中的不同系数需要采取不同的量化精度。

##### Z字扫描

Z字扫描(Zigzag Scan)，由于量化过程。如果数据可以被期待在某一个区域中的相似特征出现频率较高而非沿着直线行进，则采用Z字扫描可以有效提高压缩效率，因为聚集在一起的特征只需要保存其差异即可，而非保存所有特征的所有信息。

##### 游程编码

游程编码(RLE,Run Length Encoding）来源于一种简单的思想，用变长的编码来取代连续出现的重复信息，譬如 “AAABBBBCCDEEEEE”，即可被压缩成“A3B4C2DIE5”，应用于音视频领域时，它需要输入的是经过变换,连续重复数据较多的情况。

##### 熵编码

熵编码(Entropy Encoding）与游程编码均是无损压缩方法,主要类型的熵编码方式对每一个符号创建并分配唯一的前缀码，并替换成可变长度前缀无关的输出，霍夫曼编码即是熵编码的一种，算术编码也属于熵编码,为得到好的压缩效果，需要尽可能精确地知道每个输入单元出现的概率，而对概率的估计越准确，压缩效率就越高，此时既可以在压缩前进行全文统计，亦可以动态计算,如按照已经编码的概率计算,还可以计算未编码部分的概率等。

##### 运动估计

运动估计，主要用于描述编码关系上相邻的两帧差别。即前一帧每个块如何移动到后面一帧，设法搜索到它们之间的相对偏移，即所谓运动矢量,利用运动矢量,将参考帧的宏块移动到对应位置，即可生成被压缩图像的预测，因为在自然情况下，通常运动存在一定规律,故预测图像和被压绪图像之间差分值较低，可以帮助去除帧间冗余度。

##### 码率控制

码率控制。视频的码率越高，往往质量越高,但为了减少传输和存储的成本，人们希望压缩得到的视频越小越好，故而设置合适的码率,取得质量和大小的平衡就非常重要,好的编码器可以让编出的视频尽可能符合预先设置的码率,不同的编码器会采取不同策略来控制所编视频的码率,不仅控制其中某一视频片段的码率,也包括整体输出的文件大小。

### 图片编码

在算法信息论(Algorithmic Information Theory)中,一个对象的柯式复杂性(KolmogorovComplexity，或称算法熵）可以衡量描述这个对象所需要的信息量，虽然并非所有图像都可以(限定失真率地）压缩，但事实上，人们在实际生活中遇到的图片基本都是可以压缩的。

- RGB
- YUV
- CMYK    打印领域
- HSL
- HSV
- NCS
- LAB

无损压缩可以元全地保留图片里的信息量,解码观看图片时和原图可做到完全一致，方法有游程编码、嫡编码或自适应字典算法等。
常见的有损方法包括色彩空间转换、色度抽样、分形压缩、DCT 或小波变换等，除高效地实现图像压缩外，好的压缩算法和格式还需要兼顾可扩展性（如质量、分辨率渐进)等目标。

#### 基本概念

##### YUV

YUV则是另外一种编码方式，其中Y表示明亮度，U表示色度,V表示浓度。

YUV  可转 RGB 。有相关转换公式

#### 格式

##### BMP

BMP是由微软开发的,常见的无损图片格式之一,内部使用的就是RGB格式,对24Bit或32Bit的RGB存储而言,数据区直接排列着每一个像素对应的RGB或RGBA的值(顺序实际为BGR和 BGRA),但如同前文提到的，无损图片文件体积很大，一个800像素×600像素的24Bit图片需要占据约1.4MB的空间，并不是很适合在存储或传播的场合使用。PNG是另一种无损压缩的图片格式，由 RFC2083标准描述,其中最广为人知的是它对 Alpha通道的透明/半透明特性的支持，同样，因为体积较大,也仅适合在非常需要半透明效果的场合。

##### JPG/JPEG

JPG/JPEG是值得重点关注的有损压缩的图片格式，它已流行多年，主要思路是舍弃人眼难以感知的颜色（高频)信息。JPEG格式里面支持的是 YUV 类型的图像，**可以支持顺序式或渐进式**(推荐使用,在下载时用户可以先看到模糊但完整的图片)编码，以及**阶梯式编码**。在图像压缩时，JPEG 文件首先将图像的模式转换为YUV，随后进行DCT 变换，将图像分离出高频和低频信息，对变换后的频率系数再进行量化,其中选取合适的质量因子可以决定编码完成的图像质量,最后按照 Z字形对矩阵中的值进行游程编码。使用 JPEG 格式额外的有利之处在于,许多浏览器或硬件设备对JPEG文件的渲染早有针对性的优化，对用户在客户端的体验大有好处。
当使用JPEG格式时，可以考虑以下一些优化思路，譬如选取活合的色度抽样会影响图像在同样质量水平下的大小，因为人眼对光亮度十分敏感,但对色度的细节损失则反应较迟钝。此外,在生成 JPEG 文件时，可考虑 MozJPEG 编码器,它由 Mozilla发布，声称可以比传统JPEG编码器减少5%或10%的图片大小。

##### SVG

SVG是一种适合应用于网页的矢量图形标准。

针对有极致压缩优化需求的用户,还可以考虑 WEBP 和  BPG。

##### WEBP

WEBP衍生自视频编码格式VP8，由Google在BSD授权下开源，相比 JPEG 而言，同样质量的图片 WEBP 可节省25%~40%的大小。在 Chrome.Opera浏览器和 Android 系统上,都内置了它的支持,但其他浏览器不能直接支持则是一大弊端，意味着服务端需要针对同一图像存储不同的格式。当然，当前支持 WEBP 的浏览器市场份额在50%以上，采用这一格式可以让很多用户得到较好的网页和图片加载时间，还是比较值得的。

##### BPG

BPG格式是 FFMpeg 发起者Fabrice创建的一种图片格式，主要参考了 H.265/HEVC 的编码方法中的部分工具，它在某些情况下具有最好的压缩比,并有一个效率不错的基于 JavaScript 的解码器。在下列的一份比较测试中可见，在质量相同的情况下，压缩小图片时,BPG格式颇占优势，而针对较大的图片，WEBP不论压缩比还是(软件）解码效率都较高。还应考虑注意的文件格式包括HEIF，也脱胎于HEVC编码标准，苹果公司已在 wWDC宣布其旗下设备全面支持HEIF。

##### Guetzli

近年来,深度学习技术也被加入图像识别技术中,如Google就发布了名为Guetzli的项目，在兼容JPEG 格式的情况下,可以显著地降低图片大小(可见上文测试),缺点是图像压缩时间实在太长,但这不失为一种好的思路,在通过人为推导算法不容易得到提升的领域,应用较新的技术,可能会带来额外的提升。

为了得到更好的显示质量,还有一种思路是在客户端增加图片的像素,譬如用取样插值、双线性插值、双三次插值、Super Sampling 等方法来将较小的图像放大，得到较好的效果。



针对海量图片文件，则使用形如 Seaweed FS (开发思路来自于Facebook的Haystack )或 TFS (Taobao File System，淘宝文件系统)的文件系统，它们对降低IOPS.增加吞吐量可谓势在必行。实际上，由于缩略图文件的特性(若干缩略图均来源于同一视频文件,具备时序相关性,缩略图往往针对系列文件进行顺序请求)，还可以进行更有针对性的优化,达到更大的并发请求性能。

此外，在网页中指定预加载链接（\<link rel=preload>)，对重要的图片采用 CDN 分发(Netflix也使用了Cloudinary和 imgix等图片CDN服务)，延迟加载非重要的图片等策略也是在线视频网站必须纳入考量的内容。



### H.264/AVC

H264 定义了1~6.2 一系列的Profile等级，每个Profile都有其不同的分辨率、码率、帧率等范围。

H.264当前主要支持 YUV420 和 8Bit 精度(较新修订的标准增加了对 10Bit 的支持)，其输入单位是帧或场(Field)，当针对隔行扫描的视频帧时，需要引入**场**的概念。H.264支持固定帧编码、固定场编码、图像自适应帧/场编码（PAFF）和宏块自适应帧/场编码(MBAFF)。H.264中每一帧可以被编成一个或多个 Slice,每个 Slice又包含多个宏块。每个宏块包含16×16的亮度像素、8×8的Cb和8×8的Cr分量。Slice分为以下类型: I Slice、P Slice、B Slice、SP Slice、SI Slice。其中I、P、B的含义较易理解，I Slice 中只包含Ⅰ宏块,P Slice中可包括Р和Ⅰ宏块,B Slice 中可包含B和1宏块，而SP和 SI Slice属于扩展功能,用于不同码率流之间的切换图3-11给出了一份示意的H.264层次划分。

H.264与下一代的 H.265十分类似，均采用**混合式编码结构**，对于空间冗余，视频帧通过变换和量化即可进行压缩，相对其他编码格式，H.264新引入帧内预测，以宏块为基本单位，将同一帧的邻近像素作为参考，产生对当前宏块的预测值，再对预测误差进行编码，提高了压缩率。为了一致化编解码，编码器使用的预测数据是经讨后亦挽和量化后的重建图像。对于时间冗余,编码器利用连续帧进行运动估计和运动补偿。下面分别介绍H.264的主要技术,包括预测、变换、量化、环路滤波和嫡编码。

#### 编码过程

##### 编码步骤

- 预测
- 变换
- 量化
- 环路滤波器
- 熵编码

##### 预测

首先是帧内和帧间预测,编码器在此引入了大量特性。对于**帧内预测**,H.264先根据相邻的宏块进行预测，包括**1种直接预测和8种方向预测**。针对**帧间预测**，H.264在邻近帧中寻找和该块最为相似的块,常用的方法包括**全匹配法**、**二维对数法**、**三步搜索法**、**邻域搜索法**、**菱形搜索法**等。对每一个16×16的宏块，运动补偿可以采用不同的大小和形状，共7种模式(即16×16、16×8、8×16、8×8、8×4、4×8、4X4，通过RDO（率失真优化）方法选择得到)。对每一种分割都尝试在搜索范围内寻找估计块，计算代价，选择最小代价的分割进行预测编码。计算匹配的方法包括SAD（绝对误差法)、SATD(经哈德曼变换的残差绝对值和)、SSD(平方差和)等。

进行运动估计时，可先用整像素精度进行搜索，找到最佳匹配块后，再在该位置周围进行1/2像素乃至1/4、1/8像素精度的搜索以寻找最佳匹配点，即所谓的树状分级搜索。通过树状搜索找到最佳匹配点后,根据最佳匹配块和当前块的位置，计算得到运动矢量。根据周围的块对MV进行预测也可以得到预测MV (即 MVp)，最终被编码的对象是运动矢量的插值MVD-MV-MVp。

此外,在预测中,编码器还支持运动矢量超出图像边界，支持多帧预测，可选择5个不同的参考帧,取消了参考图像和现实图像顺序的相关性,允许进行加权预测，对跳过区域的运动采用推测方法进行以及对B帧采用直接运动补偿等多项特性。

##### 变换

在变换和反变换环节,H.264采用**基于4×4像素块的整数DCT变换**，与浮点运算相比,整数DCT 变换会带来一些额外误差，但也避免了取舍位数造成的误差，总体影响不大，而换得减少运算复杂度的好处。标准同时支持分级块变换，譬如低频色度信号可用8×8像素块，低频亮度信号可用16×16像素块等。不同于以往编码器中变换与反变换间存在的误差,H.264实现了完全匹配。

##### 量化

在变换之后需要对数据进行量化,量化的意图是通过多对一的映射以降低码率,包括均匀和非均匀量化、自适应量化。在H.264中对亮度(Luma)可选 52 种不同的量化步长，QP取值为 0~51，对色度（Chroma）可取 0~39。当OP取 0 时意味着最精细，取最大值意味着最粗糙。H.264采用标量量化技术，将每个图像点映射成一个较小的数值，量化公式为 Z=round(Yᵢⱼ/Qₛₜₑₚ)，其中Zᵢⱼ 不是量化后的系数，round() 代表取整，Yᵢⱼ 是变换后得到的系数，也即量化的输入，Oₛₜₑₚ 是量化步长。在量化后，数据经过 Z字扫描或双扫描（仅在较小量化级的块内使用)存储。

##### 环路滤波器

由于包括H.264在内的许多视频编码器都基于宏块，存在变换和运动补偿导致的块效应(即视觉上不连续的沿块边界)，如果不进行处理，这些不连续性将随着预测过程扩散，环路滤波可以有效消除块效应，是编码过程中极为重要的一环,这项技术又被称作 De-blocking Filter(去块效应滤波）或 Reconstruction Filter(重构滤波)。由DCT变换时，高频系数被量化为 0 的形式，导致边缘在跨界处出现锯齿，称为梯形噪声，另一种因量化导致平缓的亮度块DC系数发生跳跃，造成平坦区域的色调改变，称为格形噪声。环路滤波针对亮度宏块和色度宏块进行，按先亮度后色度，先垂直后水平进行,过程如下。

1. 估算边界强度,即根据边界位置以及宏块信息估计两边的像素差距。
2. 区分真假边界,即边界是块效应导致还是视频图像原有边界。
3. 滤波运算，根据边界类型不同采用不同的算法,改变2~6个不同的像素。

##### 熵编码

H.264支持两种不同的基于上下文的熵编码方式，即在所有 Profile 上适用的 CAVLC(又称作 UVLC）和在中高档Profile上可以选择的CABAC。其中 CAVLC除量化系数外，使用统一的编码表,未考虑编码符号间的相关性，与使用编解码器共享特征（譬如运动矢量)，建立随视频帧统计特性调整的概率模型的CABAC方法比较，压缩性能要略差一些，但算法复杂程度较低。

#### 网络封装

在数据的格式定义上,H.264支持NAL结构，支持灵活的参数集结构、宏块和 Slice排序等，可以具备较强的纠错能力和网络操作灵活度。其中NAL (Network Abastraction Layer,网络抽象层)定义可让其编码的数据在各种类型的网络上传输，最为工程人员所熟悉。

NAL的定义中,每一个包称作NAL Unit,包含NALU Header和RBSP(Raw Byte SequencePaylaod)。NALU 的 Type取值为0~31，定义了该包是用来传输数据还是编码数据。一种常用对H.264的打包方式是将其NALU封装到RTP包内。对SPS、PPS等内容可将多个NALU包组合成一个RTP包，对相同时间载的NALU包，也可放于一个 RTP 包内。又或者一个NALU包可以对应一个RTP包，也可以拆成多个RTP包进行传输。

| NAL 单元语法 | 包类型    | 包类型名称   | 章节 |
| ------------ | --------- | ------------ | ---- |
| 0            | 保留类型  |              |      |
| 1-23         | NAL单元包 | 单NAL单元包  |      |
| 24           | STAP-A    | 单时间聚合包 |      |
| 25           | STAP-B    | 单时间聚合包 |      |
| 26           | MTAP16    | 多时间聚合包 |      |
| 27           | MATP24    | 多时间聚合包 |      |
| 28           | PU-A      | 片段单元     |      |
| 30-31        | 保留类型  |              |      |

#### 基础概念

##### SPS

SPS (Sequence Parameter Set，序列参数集）描述了作用于一系列图像的参数集。

##### PPS

PPS(Picture Parameter Set。图像参数集）描述了一个或多个独立图像的参数集。

#### X264

在H.264的编码实践中，不论是入门使用、学习研究，还是商业项目，都可以考虑从最广泛应用的开源编码器x264开始。x264提供了 UI工具和命令行工具，后者较为常用，它提供了多种参数供人使用,其中包含一些预先设置的参数集合，所有参数亦可以手动设置，覆盖预设参数集合中的一个或多个参数。由于x264已被集成到FFMpeg 中，通过 FFMpeg也可以灵活调用，但二者命令参数并不相同。
x264的预设参数从快到慢包含 ultrafast、superfast、veryfast、faster、fast、medium、slow、slower、 veryslow, placebo 10个集合，而 --tune 参数可以针对 film、 animation、 grain. stillimage、psnr、ssim、fastdecode、zerolatency等不同视频源或场景进行特定优化。
x264和 FFMpeg 部分调用参数的比较和释义如表3-2所示。

| 序号 | x264选项                  | FFmpeg选项                      | 释义                                  |
| ---- | ------------------------- | ------------------------------- | ------------------------------------- |
| 1    | -keyint                   | -g                              | 指定IDR帧间的最大间隔                 |
| 2    | -min-keyint               | -keyint_min                     | 指定IDR帧间的最小间隔                 |
| 3    | -bitrate                  | -b                              | 指定生成的视频码率大小                |
| 4    | -ref                      | -refs                           | 控制解码缓冲区《参考帧）数量          |
| 5    | -vbv-bufsize              | -bufsize                        | 设置vbv缓冲的大小                     |
| 6    | -vbv-maxrate              | -maxrate                        | 设置vbv模式的最大码率                 |
| 7    | -vbv-init                 | -rc_init_occupancy              | 设定vbv缓冲的初始大小                 |
| 8    | -pass                     | -paSS                           | 设置多重压缩模式,合理分配码率         |
| 9    | -crf                      | -crf                            | 固定质量参数                          |
| 10   | -qp                       | -cqp                            | 设置量化模式                          |
| 11   | -bframe                   | -bf                             | 最大连续B帧数目                       |
| 12   | -no-cabac                 | -coder                          | 选择熵编码方式                        |
| 13   | -trellis                  | -trellis                        | RD量化，需要CABAC                     |
| 14   | partitions                | partitions                      | 块划分，如p8X8、i4X4等                |
| 15   | -deblock                  | -deblockalpha<br />-deblockbeta | 设置deblock参数，包括tenghinghreshold |
| 16   | -qpmin                    | -qmin                           | 设定QP的下限                          |
| 17   | -qpmax                    | -qmax                           | 设定QP的上限                          |
| 18   | -qpstep                   | -qdiff                          | 设定QP的步长                          |
| 19   | -qcomp                    | -qcomp                          | 压缩曲线设置，与cr搭配使用            |
| 20   | -qblur                    | -qblur                          | 减小QP的波动(曲线压缩后)              |
| 21   | -cplxblur                 | -complexityblur                 | 减小QP的波动(曲线压缩前)              |
| 22   | -diret                    | -direetpred                     | 直接预测方法                          |
| 23   | -b-bias                   | -bframncbias                    | 设置B帧的使用频繁程度                 |
| 24   | -scenecut                 | -sc_threshold                   | 指定强制使用IDR帧的值                 |
| 25   | -me                       | -me_ method                     | 控制运动估计的搜索方法                |
| 26   | -merange                  | -me_range                       | 控制运动估计的搜索范围                |
| 27   | -subme                    | -subq                           | 子像素动态预测模式                    |
| 28   | -nr                       | -nr                             | 降噪处理                              |
| 29   | -level                    | -level                          | 指定编码器level                       |
| 30   | -ratetol                  | -bt                             | 允许最终码率偏离指定码率的比值        |
| 31   | -ipratio                  | -i_qfactor                      | 控制 I 帧与P帧间的量化比              |
| 32   | -pbratio                  | -b_qfactor                      | 控制P帧与B帧间的量化比                |
| 33   | -chroma-qp-offset         | -chromaoffset                   | chroma与luma的QP偏差                  |
| 34   | -no-chroma-me             | -cmp                            | 在动态预测中忽略chroma                |
| 35   | -no-deblock<br />-deblock | -flags -/+loop                  | 是否开启deblocking                    |
| 36   | -b-pyramid                | -flag2 +bpyramid                | 允许其他帧参考B帧                     |
| 37   | -weightb                  | -flags2 +wpred                  | 允许对B帧进行加权预测                 |
| 38   | -mixed-refs               | -flags2 +mixed_refs             | 对宏块进行参考帧判断                  |
| 39   | -8x8det                   | -flags2 +dct8x8                 | 自适应空间变换的大小                  |
| 40   | -no-fast-pskip            | -flags2 +fastpskip              | 关闭早期的P帧检测                     |

```c
main()		//主函数
parse()		//解析输入的命令行
encode ()	//编码
x264_encoder_open()		//打开编码器
x264_encoder_headers()		//为码流添加 SPS/PPS/SEI 
x264_encoder_encode()		//编码
x264_slice_write()			//编码S1ice
x264_slice_header_write()	//编码
x264_macroblock_analyse()	//核内成帧间宏块的预测
x264_mb_analyse_intra() 	//帧内预测
x264_mb_analyse_inter_***()		//帧间预测
x264_fdec_filter_row()		//滤波
x264_macroblock_encode()	//变换和量化
x264_macroblock_write_cabac()		//进行CABAC编码
x264_macroblock_write_cavlc()		//进行CAVLC编码
x264_ratecontrol_mb()		//码率控制
x264_encoder_close()		//关闭编码器
```

### HEVC/H.265

HEVC采用与H.264相似的混合编码架构，包含帧内和帧间预测、变换和量化、去区块滤波和嫡编码等，但在绝大多数环节上进行了大幅度的更新，加入了许多新的解码工具，可以支持4K甚至8K分辨率，下面介绍它与H.264的主要区别。

#### 基本概念

##### Skip

Skip模式是Merge的一种，其MVD均为0,而Skip模式中预制残差也为0或可以舍去，故而只需要编码运动矢量参考块的位置即可，此外Skip模式只针对2NX2N的PU划分模式。

##### CRA帧

CRA (Clean Random Access)帧，这是一个 I 帧，但它可以参考 CRA之前的帧，不需要刷新解码器。

##### RASL帧

RASL(Random Aces Skipped Leading)帧，RASL 帧是CRA帧的前导，可以参考关联的CRA帧之前的帧，因此IDR
帧只能有RADL的前导，CRA则可有RADL和RASL作为前导。

##### RADL帧

RADL (Random Aces Decodable Leading)帧，它是IRAP帧的前导，只能参考关联的IRAP帧和对应的RADL帧。

##### BLA帧

BLA (BrokenLink Access)帧，当访问CRA帧时，RASL 需要参考CRA编码顺序之前的帧，但实际并无法获得，则
被定义为BLA帧，此时舍弃其前面的所有帧。

#### 编码过程

##### 块划分

在编码架构中，与之前以宏块为基础不同，HEVC引入了**CU** (Coding Unit,编码单元)、**PU** (PedictUnit,预测单元)和**TU** (Transform Unit,转换单元)的概念。一幅图像仍然可以被划分成多个Slice,每个Slice可以进一步划分为多个Slice Segment (SS),其中包括一个独立 ss 和多个参考 ss ，每个Ss则还可包含至少一个 CTU (Coding Tree Unit,编码树单)。
此外，HEVC还将图像划分为 Tile,但与Slice不同，Tile 的形状只允许为长方形，每个Slice的CTU都属于某一个Tile,或每个Tile的CTU都属于某一个 Slice，二者必居其一。
CTU的大小由编码器指定，可以较原先的宏块为大，每个CTU包含亮度CTB (Coding Tree Block)和对应的色度CTB，尺寸可达64X64，而编码器支持使用类四又树的结构将 CTB划分成更小的块(见图3-20)。在CU结构下，可以再划分PU和PB,类似地CU也可再划分为更小的TB。

##### 预测

对于帧内预测，HEVC提高到了35种帧内预测模式，对帧间预测引入了Merge、Skip、AMVP等模式。HEVC仍然支持1/4 亮度像素精度和1/8色度像素精度的MV,对1/2 像素和1/4像素使用八阶或七阶滤波器而对1/8 像素位置定义了一种四阶滤波器，对所有分像素位置使用独立的插值，不再支持隐式的权值预测而必须显式地发送缩放或位移后的预测值。
	预测编码通过预测模型消除像素间的相关，对实际图像与预测值之间的差值再行编码和传送，如输入为像素 x(n)，则首先利用已编码像素的重建值得到当前像素的预测值p(n)，对二者的差值d(n)= x(n)-p(n) 进行量化和熵编码，同时对量化后的残差与预测值p(n)得到当前像素的重建值 x'(m) 以待后用。
	在HEVC的编码中，帧内预测模支持s种大小的PU,包括4X4、8X8、16X16. 32X32、64X64,共计支持包括33个角度的方向预测、DC预测和Planar预测等35种模式。当选择进行帧内预测时，每个PB都具备自己的帧内预测模式，具体预测过程则以TU为单位，PU 可以按照四又树形式划分 TU,且同- PU内所有TU共享同模式，首先获取相邻参考像素，当像素不存在或不可用时使用邻近像素进行填补，其次对不同的TU选择不同数量的模式进行滤波，随后利用不同的预测模式得到计算像素值。
	帧间预测编码与帧内预测相似，区别在于其利用的参考像素来源于已编码的前后多帧的数据。其中运动矢量即欲编码的像素与参考像素之间的位移，不仅将用于运动补偿，也将传递到解码器以便重建图像。
	在HEVC中，使用全搜索及 TZSearch 算法进行运动估计，针对MV的预测使用Merge模式和AMVP模式两种新的模式。Merge模式同时利用时间域和空间域上相邻PU的运动参数，当前PU的MV由直接计算候选MV并选取失真率最小者得到，不存在运动矢量残差 MVD，而AMVP模式(Advanced Motion Vector Predictor,即运动矢量预测)同样使用候选MV列表，区别在于在对选出的最优预测MV进行差分编码，获取MVD。

##### 其他编码技术

​	在变换量化时，编码标准支持基于四叉树结构的自适应变换技术( Residual Quad-treeTransform, RQT), 为最优TU模式提供了很高的灵活性，在能量集中和保留细节方面给予平衡，并支持将变换和量化过程相互结合，滤波模块则引入了SAO(Sample Adaptive Offset,采样自适应补偿)技术改善振铃效应。
​	此外，值得一提的新技术还包括ACS和IBDI. ACS技术(Adaptive Cofficient Scanning,自适应系数扫描)包括对角、水平和垂直扫描，它将一个TU划分成4X4块，按照相同顺序进行扫描，对帧内预测区域的4X4和8X8大小的TU,当预测接近水平方向时采用垂直扫描，反之接近垂直方向时选用水平扫描，其他方向或帧间预测时使用对角扫描，如此针对不同情况，采取不同扫描方法。
​	IBDI (Intemal Bit Depth Increase,内部比特深度增加)在编码器的输入端将像素深度增加，并在解码端将像素深度恢复至原有比特数，以提高编码精度，并降低帧内和帧间预测误差。
​	最后，HEVC只使用CABAC进行熵编码，由于引入并行处理架构，速度较以前得到很大改善。

#### 封装

在HEVC中仍然支持NAL层，分为VCL和Non-VCL NAL两类，对应一个每帧图像的数据和与多帧图像相关的控制信息。Non-VCL NAL包含VPS (Video Parameter Set,视频参数集)、SPS和PPS。

在H.264中可以通过IDR帧实现随机访问，HEVC里定义了新的CRA帧、RASL帧、RADL帧、BLA帧等概念。

### VP9

VP9的开发肇始于2011年，在2013年被集成到Chrome浏览器中，相比VP8有着巨大的提升，它支持Profile 0~3 四种编码配置，其中Profile 0支持4:2:0, Profile 1支持硬件播放环境及4:2: 2和4: 4: 4采样，Profle 2和Profile3支持10bit 采样。当前除YouTube外，Netflix 也在Android等支持的设备上大量应用了VP9格式。

VP9将图像分成64X64大小的Super Block,与HEVC类似，可以使用四叉树编码结构水平或垂直细分Super Block的结构直至4X4大小。

VP9的帧内预测遵循TB分区，编码器支持10种不同的预测模式，包括直流、水平、垂直、TM 以及6个定向的预测模式，在PB范围内，扫描每一个4X4的TB进行预测和重构。帧间预测使用1/8像素进行运动补偿，支持NEW、NEAR、NEAREST、ZERO四种预测模式，允许建立包含两个矢量的候选参考MV列表并以此进行选择预测，并支持在部分帧中使用复合预测(即双向预测的变体)。针对每个块可以选择3种不同的子像素插值滤波器，分别适应于高对比场景，保留其边缘尖锐部分以及相邻帧某处非自然不致的尖锐情况。此外，在VP9中当前帧和参考帧允许不一致，可使用Scale factor 进行缩放。

​	VP9格式支持3种变换类型，包括DCT、ADST (非对称离散正弦变换)和哈夫曼变换。对于帧内编码，ADST 被用于和DCT结合形成维混合变换类型，哈夫曼变换的场景则是在低量化值时进行无损编码。编码器提供了8bit. 10bit. 12bit 三个量化表，根
据不同变换类型使用不同的扫描类型。

对编码环节，VP9采用8位算数引擎编码，若给定一个n元码表即可建立-棵二进制树，通过遍历这棵树并利用上下文模型进行编码。编码器引入了Segment 的概念，Super Block 拥有相同属性时拥有同样的ID,每帧图像限制为8个不同的Segment ID,其属性包括量化因子、环路滤波强度、预测时的参考帧、TB大小和是否为Skip模式等。

VP9使用与HEVC相似的架构，并采用些独特 的技术使得二者在压缩效率上各有千秋，利用libvpx与libeve(前者系开源VP9编码器、后者系商业VP9编码器)编码均比x265在高分辨率情况下有一-定优势，而远远超过H.264的编码效率。

### AV1

AOM 开放媒体联盟。

​	AV1同样使用Super Block，按四又树结构组织，可被分割到 4X4 的块，帧内和帧间的变换均可最小使用4X4块，但最大支持的块扩展到128X128的大小，并允许10种分割方式。当进行帧内预测时，编码器支持56个角度的通用预测，参考选定方向的像素，应用1/256像素精度的 2-tap 线性滤波器，在每个可用角度查表，支持Paeth预测、Smooth预测和Palette预测。

​	进行帧间预测时，AVI 从相邻的一系列MV中指定索引，为列表中的MV按远近和与当前块的重叠量进行排序，对所选的MV索引进行编码。与 VP9 允许指定3个参考帧不同，AVI缓存8个参考帧，针对每个块允许使用7个参考帧。Overlapped Block Motion Compenstion(即重叠块运动补偿)可能是编码器使用的较复杂的技术之一，它利用邻居的预测值改进当前块的预测，以在接近边界处得到更好的预测，以及得到更为平滑的预测及残差。

​	针对全局或扭曲的运动，编码器使用特征匹配和 RANSAC (随机抽样一致性算法) 计算每个参考帧的全局运动参数，支持多种运动模型和自由度。Guided Restoration 技术让编码器在编码前降采样，在更新前再升回，并进行环路恢复，可以带来较高的增益。此外AVI 还允许对水平和垂直方向上的插值过滤器进行独立选择。

​	AV1在变换、量化和编码环节，支持DCT、ADST、反向ADST和Idcntity四种变换方法，增加了针对4X8、8X4、8X16、16X8、16X32、32X 16等矩形块的转换:支持非线性量化和 Delta QP Signaling技术；在滤波时，和VP9不同，AVI针对每个颜色空间的滤波器Level都可以不一一样；最后，其熵编码环节用15bit表示概率，允许对每个符号进行概率更新。

​	AVI在编码流程中加入了不同的Filter 工具和后处理过程，主要包括CDEF (约束方向增强滤波器)、环路恢复滤波器、超分辨率处理和胶粒合成。

### H.266

​	H.266自2016年以来进入提案征集过程，可以观察到不同的聚焦方向和许多有意思的内容。例如，H.266 更加注重4K及以上的分辨率，按l0bit处理像素，支持更大的结构单元(256X256)和变换块(64X64)， 它取消了CU、PU和TU的区别，统称为编码单元，采用QTBT (四叉树二叉树)划分，其中Y分量和UV分量独立。

​	在帧内预测时，H.266 计划拓展到65种角度(见图3-28)，采取两个阶段的模式判别过程。当帧间预测时，引入仿射和FRUC模式，其中仿射针对淡入淡出、旋转、视角运动建立模型，有较好的效果，FRUC模式提供两项解码端导出运动信息的技术TM (Template Matching)和BM (Bilateral Matching)。

​	在变换环节，提案中试图引入DST7、DST8、DSTS和DST1等变换方法，对不同变换核根据RDO结果选择最佳结果，并描述了SDT (Signal Dependent Transform)技术，通过 K-L 变换挖掘相邻帧间相邻的块。

### 视频质量评价

#### 主观评价

夹视频的主观质量评估， 需要选择批测试者， 让他们连续观看一组测试视频，通常时间在10~30分钟，让他们对视频质量进行评分，最终求得平均分后再对数据进行分析，测试时需要注意控制观看距离、观测环境、视频选择、观看顺序等。

#### 客观评价

- FR (Full Reference，全参考方法)
- RR(Reduced Reference，半参考方法)
- NR(Non Reference，无参考方法，也称为 Blind)

客观质量评价中，全参考视频质量评价比较了处理前后视频中每帧图像、每个像素的差别并给出评估结果；半参考方法则是用某种方式提取两段视频的一些特性， 比较这些特性并给出评价；无参考方法则不依赖原视频进行评价，通常考虑的是图像和视频的块效应与模糊效应，全参考和半参考方法都需要获得处理之前的视频才能进行，依赖于从视频中提取到特征的无参考方法则常常需要知晓编码的过程甚至编码器的详细设置。

##### 全参考

- PSNR（Peak Signal to Noise Ratio，峰值信噪比）
- SSIM（Structural Similarity，结构相似性）

**PSNR**

PSNR表示了信号的最大可能功率和影响它精度的噪声功率的比值，其单位通常为对数分贝。如果定义了MSE (均方差),则可以容易地定义PSNR。

对于 8Bit的图像和视频压缩，典型的视频 PSNR 值在 20~ 50dB,越接近 50dB,则认为损失越小，图像和视频越可保留原有信息。

**SSIM**

SSIM的设计思路更着重于比较处理前后两帧图像结构上的相似度，从图像组成的角度将结构信息定义为独立属性，失真度由亮度、对比度和结构三个维度估计,其中以均值作亮度估计，以标准差作对比度估计，以协方差作结构相似度的估计，取值范围为 -1~1 , 当两个信号完全相等时结果为1。

实际运用中，为保证PSNR和SSIM的意义,最好可以保证使用相同的原视频和同类型编码器，并且注意使用的编码参数，譬如与去噪和去闪烁滤波不同，去抖动滤波通常可以大幅影响 PSNR 值，但观看者反而认为图像质量得到了提高。

PSNR和SSIM可以通过**FFMpeg**在处理视频的同时进行计算，并在**OpenCV**框架中有对应的实现，**EvalVid** 也是一个常用的开源视频质量评价工具。

**FFmpeg**

> ffmpeg -i t2.png -i t2.jpg -filter_complex "psnr" -f null -
>
> ffmpeg -i input.mp4 -flag +loop+psnr out.mp4
>
> ffmpeg -i black.mp4 -x264-params ssim=1 out.mp4

由于PSNR和SSIM均针对图像计算，视频编码的对应值系全部帧的PSNR与SSIM合计得到，故而同样评分的VBR (可变码率)实际通常比CBR (固定码率)编码质量略好，这一因素在参数调优过程中不应被忽略。