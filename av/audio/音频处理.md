## 音频处理

##### 语音处理算法

​	多级滤波
​	回声处理算法
​	噪声抑制算法
​	自动增益控制算法
​	频带扩展算法
​	啸叫控制算法
​	丢包补偿算法
​	音频编码



AEC
	回声消除三步走
		信号对齐
			速度快，对的准
				时间戳
				查找对齐
				指纹对齐
			

			播放信号跟采集信号对齐，因为它们两个可能延时很大，我们都知道滤波器的阶数是有限，所以要先对齐，再滤波。信号对齐的方法一般是先用时间戳做一个粗对齐，然后再根据能量谱查找对齐，比如寻找相似性，这个其实像在开源的WebRTC里面也有。
			
		收敛速度
			自适应滤波器（优化步长控制：引入灵活因子）
				收敛快（声学路径改变）
				稳得住（双讲不发散）
				能力强（消除更多回声）
			通过改变波长来控制自适应滤波器的更新因子，并不存在双讲会导致发散的问题。
		残留回声抑制
			NLP 处理方案
				降噪多（消除更多回声）
				双讲通透
				设备非线性回声消除
	特殊频带的特殊处理
			低频保护，保证语音听感连贯性
			2kHz以下都被降噪了，2kHz以上成份是回声的可能性极大
			比如有些设备，在1k-2kHz容易产生非线性成份
	
	基于高频估计:
		根据低频特性估计高频回声
		双讲情况高频信息有遗失
		运算复杂度低


ANS-基于能量最小值跟踪法
	时域拖尾
	突发噪声
	抑制风噪
	抑制混响

AGC
	小声音放大
	大声音不爆音
	底噪不被放大过多
	

	本底噪声估计
	语音检测
	排除采集的回声影响

啸叫检测抑制算法
	产生自激振荡，需要满足相位、幅值两方面的条件
		相位：
												的极值点落在虚轴，且共轭对称，从而有：
								，其实就是同向位。
		
		幅值：
			整个反馈的幅值需要将信号放大：C(w)→K→G(w) 增益：|C(w)G(w)K|有：




	啸叫检测
		啸叫频点的检测，必须结合啸叫的时域和频域特征来进行分析。
		频域上，啸叫频点功率很高，是一个峰值，远超其他语音或噪声频率的功率。
		时域上，啸叫频点的功率有一个迅速增大的过程，达到饱和幅度后一直保持。
		
		啸叫检测特征
		1. 峰值阈值功率比(Peak-to-Threshold Power Raio, PTPR)
				啸叫的功率远大于正常播放的音频。故设定一个阈值，只有功率超过阈值的频点，才会进行啸叫检测，减少无意义的检测判决。


​				
​				
​			2. 峰值均值功率比(Peak-to-Average Power Raio, PAPR)
​				产生啸叫的频点功率远大于其他频点的功率，故可以先计算出整个频谱的平均功率，然后计算每个频点功率与平均功率之比。比值大于预设阈值的频点，记为候选啸叫频率。


​				
​			3. 峰值邻近功率比(Peak-to-Neighboring Power Raio, PNPR)
​				PNPR寻找功率谱的峰值点，加入候选啸叫频率。可以选取左右各M个相邻频点进行比较，当前频点功率比邻值都高时，记为候选啸叫频率。M选取5点左右


​				
​			4. 峰值谐波功率比(Peak-to-Harmonics Power Raio, PHPR)
​				语音谱有谐波峰，而啸叫频率是不含谐波峰的，故可以根据一个峰值点的谐波频率功率是不是也很大，来判断该峰值是否啸叫点。


​				
​				
​				
​				
​			5. 帧间峰值保持度(Interframe Peak Magnitude Persistence, IPMP)
​				IPMP是时域特征，如果一个频点，连续几帧都是检测出来的候选啸叫峰值，那就认为这个点确实发生了啸叫。实现时可以选定5帧，超过3帧是候选啸叫频点的位置，判定为啸叫点。


​				
​			
​			6. 帧间幅度斜率偏差度(Interframe Magnitude Slope Deviation, IMSD)
​				IMSD也是时域特征，是从啸叫开始发生时判断，这是啸叫频点幅度线性增长，那么帧间斜率就会保持不变。取Qₘ帧进行区间观察，计算Qₘ帧平均斜率，与区间内更短区间的斜率之间的差值，如果差值在设定阈值以下，就认为该区间斜率保持不变，可能是发生了啸叫。


​				
​				
​				
​				
​				
​				
​				
​				
​			
​			频域特征PTPR PAPR PNPR PHPR都是对一帧内频点进行分析，而时域特征是对多帧间的特征进行分析。所以在进行判决时，一般先对每帧频谱进行频域特征分析，然后对累计的时域特许证进行分析。
​	
			为了不影响原音频的频谱、以及限制滤波器计算量考虑，最后还需要限制啸叫频点的数量。一般系统可以选择五六个频点，简单的系统也可以尝试只选择啸叫程度最严重的一个或者两个频点。


​	
​	啸叫抑制的方法，主要有三种：
​		频移/相移法
​			相位就是频率，频率就是相位，该方法可以破坏相位特性，有一定失真。
​		陷波法
​			陷波法就是要在声反馈系统的极点频率插入一个陷波滤波器，抑制极点的增益，使之无法达到啸叫的增益条件。
​			
			陷波法需要分成两步：第一步，啸叫检测，将产生啸叫的频率找出来； 第二步，啸叫抑制，在找出来的啸叫频率设计陷波滤波器，并对麦克风信号进行滤波。
			
			通过窄带滤波器/自适应滤波器进行特定频率的滤波。
			
		自适应方法


​	

#### 复杂网络下如何保证高清音频

​	Qos(Quality of Service 服务质量)
​		带宽
​		延时
​		抖动
​		丢包
​		ARC(Adaptive Rate Control)
​		网络拥塞控制
​			GCC1:
​				是一个基于接收端的算法。GCC1核心算法是通过实时监控端到端延时的变化量（Jitter），从而判断当前这个网络是否趋于达到网络拥塞的情况。
​				实际上在GCC1或者GCC2里面，它真正进入系统、进入计算的这个变量不是端到端延时，而是其变化量即Jitter；Jitter=(TR(i)- TR(i-1))- (TS(i)- TS(i-1))包括前后两个数据包的接收时间戳之差再减去前后两个包发送时间戳之差，算法输入的是一个Jitter，GCC1通过Kalman自适应滤波器去除噪点，通过网络传输也好，通过整个链路传输过程也好，实际上这种延时的变化值Jitter是一种符合高斯分布的特征，当我们把噪点去掉以后就可以得出它的Jitter趋势。GCC1算法将滤波后的Jitter值与动态阈值进行相应的状态判断，从而得出当前的网络是否趋于拥塞或者处于正常，与此同时还通过实时接收到的流量和预测算法给出当前一个合理的带宽预测值。

			GCC2:
				基于发送端。它的数据处理源还是Jitter，自变量就是Jitter，应变量是什么呢？应变量是它的历史平均值。所以它对自变量和应变量做了一个最小二乘法的一元线性回归，相当于去观察当前的Jitter值相比较历史平均值有怎样的发展趋势，被称作TrendLine算法。


​		
​		FEC
​			FEC目前一般采用了Reed Solomon算法



#### 语音质量评估

​		

		回声评估指标
			1.时域上和频率上的稳定性：这里注意在双讲情况下，要关注回声处理后的效果，是否在某个时间段发散导致漏回声。
			2.回声耦合损耗：需关注声音从听筒播出来，被麦克风采集并处理后传递给对方的过程中，回声到底衰减了多少，是否还会被对方听到。
			3.回声收敛时间：需要评估算法从开始启动到工作，花多长时间收敛才能达到最佳回声处理效果
			4.反射路径变化时的回声性能：要关注通信中周围回声路径发生变化，比如对方拿着笔记本走来走去，不停晃动，这些反射路径变化会对回声处理的跟踪造成影响。
		
		噪声指标
			1.信噪比提升：关注信噪比提升的量、噪声抑制完残留的听感，以及语音本身有没有受到过多损伤，例如被消除，部分频段被抑制。
			2.特定噪声场景：要评估诸如敲键盘、点鼠标、下雨打在窗户上等特定噪声场景下的噪声抑制效果。
		
		语音质量评估模型
			有/无参考语音质量评估模型


​	
​	

资料
	啸叫抑制之陷波器: https://www.jianshu.com/p/2bb75b6f4c81	